import cv2
import numpy as np
import os
from datetime import datetime
from typing import Optional, Tuple, List
import time
import torch
from ultralytics import YOLO # ‡∏ô‡∏≥‡πÄ‡∏Ç‡πâ‡∏≤‡πÑ‡∏•‡∏ö‡∏£‡∏≤‡∏£‡∏µ YOLO

# ‡∏Å‡∏≥‡∏´‡∏ô‡∏î Path ‡∏Ç‡∏≠‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏• YOLOv5 ‡∏ó‡∏µ‡πà‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏ó‡∏£‡∏ô‡∏°‡∏≤
YOLO_MODEL_PATH = "last.pt" 
# ‡∏Å‡∏≥‡∏´‡∏ô‡∏î Class ID ‡∏Ç‡∏≠‡∏á 'parcel' ‡πÉ‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì (‡πÄ‡∏ä‡πà‡∏ô 0)
PARCEL_CLASS_ID = 0 
# ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏±‡πà‡∏ô‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡πà‡∏≥‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö
CONFIDENCE_THRESHOLD = 0.5 


class ParcelCamera:
    """Real-time camera system for capturing parcel images (YOLOv5 Integration)"""
    
    def __init__(self, output_folder: str = "parcel_images", 
                 camera_index: int = 0,
                 auto_capture: bool = False,
                 min_contour_area: int = 50000):
        """
        Args:
            output_folder: ‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏†‡∏≤‡∏û
            camera_index: index ‡∏Ç‡∏≠‡∏á‡∏Å‡∏•‡πâ‡∏≠‡∏á (0 = ‡∏Å‡∏•‡πâ‡∏≠‡∏á‡∏´‡∏•‡∏±‡∏Å)
            auto_capture: ‡∏ñ‡πà‡∏≤‡∏¢‡∏†‡∏≤‡∏û‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏
            min_contour_area: ‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡πà‡∏≥‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏û‡∏±‡∏™‡∏î‡∏∏ (‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡πÉ‡∏ä‡πâ‡πÉ‡∏ô‡πÇ‡∏´‡∏°‡∏î YOLO)
        """
        self.output_folder = output_folder
        self.camera_index = camera_index
        self.auto_capture = auto_capture
        self.min_contour_area = min_contour_area # ‡πÄ‡∏Å‡πá‡∏ö‡πÑ‡∏ß‡πâ‡πÄ‡∏ú‡∏∑‡πà‡∏≠‡πÉ‡∏ä‡πâ‡πÉ‡∏ô‡πÇ‡∏´‡∏°‡∏î manual
        
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏ñ‡πâ‡∏≤‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ
        if not os.path.exists(output_folder):
            os.makedirs(output_folder)
            print(f"‚úÖ ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå: {output_folder}")
        
        # Camera settings
        self.cap = None
        self.is_running = False
        self.captured_images = []
        
        # Detection settings
        self.detection_cooldown = 2.0  # ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ ‡∏Å‡πà‡∏≠‡∏ô‡∏à‡∏±‡∏ö‡∏†‡∏≤‡∏û‡∏ñ‡∏±‡∏î‡πÑ‡∏õ
        self.last_capture_time = 0
        
        # ROI (Region of Interest) settings
        self.roi_percentage = 0.7  # 70% ‡∏Ç‡∏≠‡∏á‡∏´‡∏ô‡πâ‡∏≤‡∏à‡∏≠
        
        # YOLOv5 Model Initialization
        self.model = None
        self.detected_parcels = [] # ‡πÄ‡∏Å‡πá‡∏ö‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡πÉ‡∏ô‡πÄ‡∏ü‡∏£‡∏°‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô
        self.load_yolo_model()

    def load_yolo_model(self):
        """‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏• YOLOv5"""
        try:
            # ‡πÉ‡∏ä‡πâ ultralytics.YOLO ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡πÄ‡∏ó‡∏£‡∏ô‡∏°‡∏≤
            self.model = YOLO(YOLO_MODEL_PATH)
            print(f"‚úÖ ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏• YOLOv5 '{YOLO_MODEL_PATH}' ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à")
        except Exception as e:
            print(f"‚ùå ‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏• YOLOv5: {e}")
            self.model = None
    
    # ... (‡πÄ‡∏°‡∏ò‡∏≠‡∏î initialize_camera, get_roi_bounds ‡∏Ñ‡∏á‡πÄ‡∏î‡∏¥‡∏°) ...
    def initialize_camera(self) -> bool:
        """‡πÄ‡∏õ‡∏¥‡∏î‡∏Å‡∏•‡πâ‡∏≠‡∏á"""
        try:
            self.cap = cv2.VideoCapture(self.camera_index)
            
            if not self.cap.isOpened():
                print(f"‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏õ‡∏¥‡∏î‡∏Å‡∏•‡πâ‡∏≠‡∏á index {self.camera_index}")
                return False
            
            # ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏Ñ‡∏ß‡∏≤‡∏°‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î
            self.cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)
            self.cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)
            
            # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏Å‡∏•‡πâ‡∏≠‡∏á‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ä‡∏±‡∏î‡∏ó‡∏µ‡πà‡∏î‡∏µ‡∏Ç‡∏∂‡πâ‡∏ô
            self.cap.set(cv2.CAP_PROP_AUTOFOCUS, 1)  # Auto focus
            self.cap.set(cv2.CAP_PROP_FOCUS, 0)  # Focus setting
            
            # ‡∏≠‡πà‡∏≤‡∏ô‡∏Ç‡∏ô‡∏≤‡∏î‡∏à‡∏£‡∏¥‡∏á
            self.frame_width = int(self.cap.get(cv2.CAP_PROP_FRAME_WIDTH))
            self.frame_height = int(self.cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
            
            print(f"‚úÖ ‡πÄ‡∏õ‡∏¥‡∏î‡∏Å‡∏•‡πâ‡∏≠‡∏á‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à - ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î: {self.frame_width}x{self.frame_height}")
            self.is_running = True
            return True
            
        except Exception as e:
            print(f"‚ùå ‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏¥‡∏î‡∏Å‡∏•‡πâ‡∏≠‡∏á: {e}")
            return False
    
    def get_roi_bounds(self, frame_shape: Tuple[int, int]) -> Tuple[int, int, int, int]:
        """‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà ROI (‡∏Å‡∏£‡∏≠‡∏ö‡∏™‡πÅ‡∏Å‡∏ô)"""
        h, w = frame_shape[:2]
        
        roi_w = int(w * self.roi_percentage)
        roi_h = int(h * self.roi_percentage)
        
        x1 = (w - roi_w) // 2
        y1 = (h - roi_h) // 2
        x2 = x1 + roi_w
        y2 = y1 + roi_h
        
        return x1, y1, x2, y2

    def draw_roi_frame(self, frame: np.ndarray, detected: bool = False) -> np.ndarray:
        """‡∏ß‡∏≤‡∏î‡∏Å‡∏£‡∏≠‡∏ö ROI, UI ‡πÅ‡∏•‡∏∞ Bounding Boxes ‡∏à‡∏≤‡∏Å YOLO"""
        h, w = frame.shape[:2]
        x1, y1, x2, y2 = self.get_roi_bounds(frame.shape)
        
        # ‡∏™‡∏µ‡∏Å‡∏£‡∏≠‡∏ö (‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ß = ‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö, ‡∏ü‡πâ‡∏≤ = ‡∏õ‡∏Å‡∏ï‡∏¥)
        color = (0, 255, 0) if detected else (255, 200, 0)
        thickness = 3 if detected else 2
        
        # ‡∏ß‡∏≤‡∏î‡∏Å‡∏£‡∏≠‡∏ö‡∏´‡∏•‡∏±‡∏Å
        cv2.rectangle(frame, (x1, y1), (x2, y2), color, thickness)
        
        # ‡∏ß‡∏≤‡∏î‡∏°‡∏∏‡∏°‡πÄ‡∏ô‡πâ‡∏ô (corner markers)
        corner_length = 40
        corner_thickness = 5
        
        corners = [
            (x1, y1), (x2, y1),  # ‡∏ö‡∏ô‡∏ã‡πâ‡∏≤‡∏¢, ‡∏ö‡∏ô‡∏Ç‡∏ß‡∏≤
            (x1, y2), (x2, y2)   # ‡∏•‡πà‡∏≤‡∏á‡∏ã‡πâ‡∏≤‡∏¢, ‡∏•‡πà‡∏≤‡∏á‡∏Ç‡∏ß‡∏≤
        ]
        
        for i, (cx, cy) in enumerate(corners):
            if i == 0:  # ‡∏ö‡∏ô‡∏ã‡πâ‡∏≤‡∏¢
                cv2.line(frame, (cx, cy), (cx + corner_length, cy), color, corner_thickness)
                cv2.line(frame, (cx, cy), (cx, cy + corner_length), color, corner_thickness)
            elif i == 1:  # ‡∏ö‡∏ô‡∏Ç‡∏ß‡∏≤
                cv2.line(frame, (cx, cy), (cx - corner_length, cy), color, corner_thickness)
                cv2.line(frame, (cx, cy), (cx, cy + corner_length), color, corner_thickness)
            elif i == 2:  # ‡∏•‡πà‡∏≤‡∏á‡∏ã‡πâ‡∏≤‡∏¢
                cv2.line(frame, (cx, cy), (cx + corner_length, cy), color, corner_thickness)
                cv2.line(frame, (cx, cy), (cx, cy - corner_length), color, corner_thickness)
            elif i == 3:  # ‡∏•‡πà‡∏≤‡∏á‡∏Ç‡∏ß‡∏≤
                cv2.line(frame, (cx, cy), (cx - corner_length, cy), color, corner_thickness)
                cv2.line(frame, (cx, cy), (cx, cy - corner_length), color, corner_thickness)
        
        # ‡πÄ‡∏™‡πâ‡∏ô‡∏Å‡∏∂‡πà‡∏á‡∏Å‡∏•‡∏≤‡∏á (crosshair)
        center_x, center_y = w // 2, h // 2
        cv2.line(frame, (center_x - 20, center_y), (center_x + 20, center_y), (0, 255, 255), 2)
        cv2.line(frame, (center_x, center_y - 20), (center_x, center_y + 20), (0, 255, 255), 2)
        
        # ‡∏ß‡∏≤‡∏î Bounding Box ‡∏Ç‡∏≠‡∏á YOLO
        for box in self.detected_parcels:
            # box ‡∏Ñ‡∏∑‡∏≠ [x1, y1, x2, y2, conf, cls] (‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô int)
            bx1, by1, bx2, by2 = map(int, box[:4])
            conf = box[4]
            # ‡∏ß‡∏≤‡∏î‡∏™‡∏µ‡πà‡πÄ‡∏´‡∏•‡∏µ‡πà‡∏¢‡∏°
            cv2.rectangle(frame, (bx1, by1), (bx2, by2), (0, 255, 255), 2)
            # ‡πÅ‡∏™‡∏î‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏±‡πà‡∏ô
            cv2.putText(frame, f"Parcel {conf:.2f}", (bx1, by1 - 10), 
                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 2)

        # Text overlay - Header
        header_bg = np.zeros((80, w, 3), dtype=np.uint8)
        header_bg[:] = (40, 40, 40)
        frame[0:80] = cv2.addWeighted(frame[0:80], 0.3, header_bg, 0.7, 0)
        
        cv2.putText(frame, "PARCEL SCANNER (YOLOv5)", (20, 35), 
                    cv2.FONT_HERSHEY_DUPLEX, 1.0, (255, 255, 255), 2)
        cv2.putText(frame, f"Images: {len(self.captured_images)}", (20, 65), 
                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (200, 200, 200), 1)
        
        # Status text
        if detected:
            status_text = "PARCEL DETECTED! (YOLO)"
            cv2.putText(frame, status_text, (w - 350, 35), 
                        cv2.FONT_HERSHEY_DUPLEX, 0.8, (0, 255, 0), 2)
        
        # Instructions - Footer
        footer_y = h - 100
        instructions = [
            "SPACE: Capture",
            "C: Clear All",
            "A: Auto Mode",
            "Q/ESC: Exit"
        ]
        
        footer_bg = np.zeros((100, w, 3), dtype=np.uint8)
        footer_bg[:] = (40, 40, 40)
        frame[footer_y:h] = cv2.addWeighted(frame[footer_y:h], 0.3, footer_bg, 0.7, 0)
        
        for i, instruction in enumerate(instructions):
            x_pos = 20 + (i * 200)
            cv2.putText(frame, instruction, (x_pos, footer_y + 30), 
                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)
        
        mode_text = f"Mode: {'AUTO (YOLO)' if self.auto_capture else 'MANUAL (Contour)'}"
        cv2.putText(frame, mode_text, (w - 250, footer_y + 30), 
                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 200, 0), 2)
        
        return frame
    
    def detect_parcel(self, frame: np.ndarray) -> Tuple[bool, Optional[np.ndarray]]:
        """
        ‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏û‡∏±‡∏™‡∏î‡∏∏
        - ‡πÇ‡∏´‡∏°‡∏î Auto: ‡πÉ‡∏ä‡πâ YOLOv5
        - ‡πÇ‡∏´‡∏°‡∏î Manual: ‡πÉ‡∏ä‡πâ Contour Detection (‡∏à‡∏≤‡∏Å‡πÇ‡∏Ñ‡πâ‡∏î‡πÄ‡∏î‡∏¥‡∏°) ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏¢‡∏±‡∏á‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡πÑ‡∏î‡πâ
        """
        self.detected_parcels = [] # ‡πÄ‡∏Ñ‡∏•‡∏µ‡∏¢‡∏£‡πå‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡πÄ‡∏î‡∏¥‡∏°
        h, w = frame.shape[:2]
        
        if self.auto_capture and self.model:
            # ‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏î‡πâ‡∏ß‡∏¢ YOLOv5
            results = self.model(frame, verbose=False, conf=CONFIDENCE_THRESHOLD)
            detected = False

            if results and len(results) > 0:
                # ‡πÅ‡∏õ‡∏•‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡πÄ‡∏õ‡πá‡∏ô tensors (‡∏Å‡∏£‡∏ì‡∏µ‡∏°‡∏µ GPU) ‡∏´‡∏£‡∏∑‡∏≠‡πÉ‡∏ä‡πâ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏à‡∏≤‡∏Å CPU
                # ‡πÉ‡∏ä‡πâ .boxes.data ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Bounding Box: [x1, y1, x2, y2, conf, cls]
                for result in results:
                    boxes = result.boxes.data.cpu().numpy() # ‡∏¢‡πâ‡∏≤‡∏¢‡πÑ‡∏õ CPU ‡πÅ‡∏•‡∏∞‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô numpy
                    
                    for box in boxes:
                        conf = box[4]
                        cls = int(box[5])
                        
                        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡πÄ‡∏õ‡πá‡∏ô 'parcel' ‡πÅ‡∏•‡∏∞‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏±‡πà‡∏ô‡∏™‡∏π‡∏á‡∏û‡∏≠
                        if cls == PARCEL_CLASS_ID and conf >= CONFIDENCE_THRESHOLD:
                            # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤ Bounding Box ‡∏≠‡∏¢‡∏π‡πà‡∏†‡∏≤‡∏¢‡πÉ‡∏ô ROI (Optional, ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Å‡∏£‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏ô‡∏≠‡∏Å‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà)
                            x1_roi, y1_roi, x2_roi, y2_roi = self.get_roi_bounds(frame.shape)
                            
                            bx1, by1, bx2, by2 = map(int, box[:4])
                            
                            # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏à‡∏∏‡∏î‡∏®‡∏π‡∏ô‡∏¢‡πå‡∏Å‡∏•‡∏≤‡∏á‡∏Ç‡∏≠‡∏á‡∏Å‡∏•‡πà‡∏≠‡∏á‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô ROI (‡∏´‡∏£‡∏∑‡∏≠‡πÉ‡∏ä‡πâ‡∏ß‡∏¥‡∏ò‡∏µ‡∏≠‡∏∑‡πà‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°)
                            center_x, center_y = (bx1 + bx2) // 2, (by1 + by2) // 2
                            
                            if x1_roi <= center_x <= x2_roi and y1_roi <= center_y <= y2_roi:
                                self.detected_parcels.append(box)
                                detected = True
                                
            # ‡∏™‡πà‡∏á‡∏Ñ‡∏∑‡∏ô‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡πÅ‡∏•‡∏∞‡∏†‡∏≤‡∏û‡πÄ‡∏ï‡πá‡∏°‡πÄ‡∏ü‡∏£‡∏°
            return detected, frame
        
        else:
            # ‡πÇ‡∏´‡∏°‡∏î Manual - ‡πÉ‡∏ä‡πâ Contour Detection ‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡πÄ‡∏î‡∏¥‡∏° (‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏Ç‡πâ‡∏≤‡∏Å‡∏±‡∏ô‡πÑ‡∏î‡πâ)
            x1, y1, x2, y2 = self.get_roi_bounds(frame.shape)
            roi = frame[y1:y2, x1:x2]
            
            # ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô grayscale ‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö
            gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)
            
            # ‡∏•‡∏î noise
            blurred = cv2.GaussianBlur(gray, (5, 5), 0)
            
            # Edge detection
            edges = cv2.Canny(blurred, 50, 150)
            
            # ‡∏´‡∏≤ contours
            contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            
            # ‡∏´‡∏≤ contour ‡∏ó‡∏µ‡πà‡πÉ‡∏´‡∏ç‡πà‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î
            detected = False
            
            if contours:
                largest_contour = max(contours, key=cv2.contourArea)
                area = cv2.contourArea(largest_contour)
                
                if area > self.min_contour_area:
                    detected = True
            
            return detected, roi # ‡∏Ñ‡∏∑‡∏ô‡∏Ñ‡πà‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡∏†‡∏≤‡∏û ROI ‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡πÄ‡∏î‡∏¥‡∏°
    
    def capture_image(self, frame: np.ndarray, auto: bool = False) -> Optional[str]:
        """‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏†‡∏≤‡∏û‡∏û‡∏±‡∏™‡∏î‡∏∏ (‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÄ‡∏â‡∏û‡∏≤‡∏∞ ROI)"""
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö cooldown (‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö auto capture)
        if auto:
            current_time = time.time()
            if current_time - self.last_capture_time < self.detection_cooldown:
                return None
            self.last_capture_time = current_time
        
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S_%f")[:-3]
        filename = f"parcel_{timestamp}.jpg"
        filepath = os.path.join(self.output_folder, filename)
        
        # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏†‡∏≤‡∏û
        try:
            # Crop ROI
            x1, y1, x2, y2 = self.get_roi_bounds(frame.shape)
            # ‡∏ï‡∏±‡∏î‡∏†‡∏≤‡∏û ROI
            roi = frame[y1:y2, x1:x2]
            
            # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏î‡πâ‡∏ß‡∏¢‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏™‡∏π‡∏á (‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏†‡∏≤‡∏û roi ‡∏ï‡πâ‡∏ô‡∏â‡∏ö‡∏±‡∏ö)
            cv2.imwrite(filepath, roi, [cv2.IMWRITE_JPEG_QUALITY, 95])
            
            self.captured_images.append({
                'filename': filename,
                'filepath': filepath,
                'timestamp': timestamp,
                'auto': auto
            })
            
            print(f"üì∏ {'[AUTO]' if auto else '[MANUAL]'} ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏†‡∏≤‡∏û: {filename}")
            return filepath
            
        except Exception as e:
            print(f"‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏†‡∏≤‡∏û: {e}")
            return None
    
    # ... (‡πÄ‡∏°‡∏ò‡∏≠‡∏î clear_captured_images, run, cleanup, get_captured_images ‡∏Ñ‡∏á‡πÄ‡∏î‡∏¥‡∏°) ...
    def clear_captured_images(self):
        """‡∏•‡∏ö‡∏†‡∏≤‡∏û‡∏ó‡∏µ‡πà‡∏ñ‡πà‡∏≤‡∏¢‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î"""
        try:
            for img_data in self.captured_images:
                filepath = img_data['filepath']
                if os.path.exists(filepath):
                    os.remove(filepath)
            
            count = len(self.captured_images)
            self.captured_images.clear()
            print(f"üóëÔ∏è  ‡∏•‡∏ö‡∏†‡∏≤‡∏û‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î ({count} ‡πÑ‡∏ü‡∏•‡πå)")
            
        except Exception as e:
            print(f"‚ö†Ô∏è ‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏•‡∏ö‡∏†‡∏≤‡∏û: {e}")

    def run(self):
        """‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏Ç‡∏≠‡∏á‡∏Å‡∏•‡πâ‡∏≠‡∏á"""
        if not self.initialize_camera():
            return
        
        print("\n" + "="*60)
        print("üì∑ ‡πÄ‡∏õ‡∏¥‡∏î‡∏Å‡∏•‡πâ‡∏≠‡∏á‡∏™‡πÅ‡∏Å‡∏ô‡∏û‡∏±‡∏™‡∏î‡∏∏ (YOLOv5)")
        print("="*60)
        print("‚å®Ô∏è  Controls:")
        print("   SPACE       - ‡∏ñ‡πà‡∏≤‡∏¢‡∏†‡∏≤‡∏û")
        print("   C           - ‡∏•‡∏ö‡∏†‡∏≤‡∏û‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î")
        print("   A           - ‡∏™‡∏•‡∏±‡∏ö‡πÇ‡∏´‡∏°‡∏î Auto/Manual")
        print("   Q / ESC     - ‡∏≠‡∏≠‡∏Å‡∏à‡∏≤‡∏Å‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏°")
        print("="*60)
        
        if self.auto_capture and not self.model:
             print("‚ö†Ô∏è **‡∏Ñ‡∏≥‡πÄ‡∏ï‡∏∑‡∏≠‡∏ô:** ‡πÇ‡∏°‡πÄ‡∏î‡∏• YOLOv5 ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏°‡πà‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à! Auto-capture ‡∏à‡∏∞‡πÑ‡∏°‡πà‡∏ó‡∏≥‡∏á‡∏≤‡∏ô")
        
        try:
            while self.is_running:
                ret, frame = self.cap.read()
                
                if not ret:
                    print("‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏≠‡πà‡∏≤‡∏ô‡∏†‡∏≤‡∏û‡∏à‡∏≤‡∏Å‡∏Å‡∏•‡πâ‡∏≠‡∏á")
                    break
                
                # ‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏û‡∏±‡∏™‡∏î‡∏∏
                detected, _ = self.detect_parcel(frame) # ‡πÉ‡∏ä‡πâ _ ‡πÄ‡∏û‡∏£‡∏≤‡∏∞ YOLO ‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏Ñ‡∏∑‡∏ô‡∏Ñ‡πà‡∏≤ roi
                
                # Auto capture
                if self.auto_capture and detected:
                    # ‡πÉ‡∏ä‡πâ frame ‡∏ï‡πâ‡∏ô‡∏â‡∏ö‡∏±‡∏ö‡πÉ‡∏ô‡∏Å‡∏≤‡∏£ capture
                    self.capture_image(frame, auto=True) 
                
                # ‡∏ß‡∏≤‡∏î UI
                display_frame = self.draw_roi_frame(frame.copy(), detected)
                
                # ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•
                cv2.imshow('Parcel Scanner', display_frame)
                
                # ‡∏£‡∏±‡∏ö‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á‡∏à‡∏≤‡∏Å‡∏Ñ‡∏µ‡∏¢‡πå‡∏ö‡∏≠‡∏£‡πå‡∏î
                key = cv2.waitKey(1) & 0xFF
                
                if key == ord(' '):  # Space - ‡∏ñ‡πà‡∏≤‡∏¢‡∏†‡∏≤‡∏û
                    self.capture_image(frame, auto=False)
                
                elif key == ord('c') or key == ord('C'):  # C - ‡∏•‡∏ö‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
                    self.clear_captured_images()
                
                elif key == ord('a') or key == ord('A'):  # A - ‡∏™‡∏•‡∏±‡∏ö‡πÇ‡∏´‡∏°‡∏î
                    self.auto_capture = not self.auto_capture
                    mode = "AUTO (YOLO)" if self.auto_capture else "MANUAL (Contour)"
                    print(f"üîÑ ‡∏™‡∏•‡∏±‡∏ö‡πÇ‡∏´‡∏°‡∏î‡πÄ‡∏õ‡πá‡∏ô: {mode}")
                    if self.auto_capture and not self.model:
                        print("‚ö†Ô∏è **‡∏Ñ‡∏≥‡πÄ‡∏ï‡∏∑‡∏≠‡∏ô:** ‡πÇ‡∏°‡πÄ‡∏î‡∏• YOLOv5 ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏°‡πà‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à! Auto-capture ‡∏à‡∏∞‡πÑ‡∏°‡πà‡∏ó‡∏≥‡∏á‡∏≤‡∏ô")
                
                elif key == ord('q') or key == ord('Q') or key == 27:  # Q/ESC - ‡∏≠‡∏≠‡∏Å
                    print("\nüëã ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏õ‡∏¥‡∏î‡∏Å‡∏•‡πâ‡∏≠‡∏á...")
                    break
        
        except KeyboardInterrupt:
            print("\n‚ö†Ô∏è ‡∏´‡∏¢‡∏∏‡∏î‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡πÇ‡∏î‡∏¢‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ")
        
        finally:
            self.cleanup()

    def cleanup(self):
        """‡∏õ‡∏¥‡∏î‡∏Å‡∏•‡πâ‡∏≠‡∏á‡πÅ‡∏•‡∏∞‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î"""
        self.is_running = False
        
        if self.cap is not None:
            self.cap.release()
        
        cv2.destroyAllWindows()
        
        print(f"\n‚úÖ ‡∏õ‡∏¥‡∏î‡∏Å‡∏•‡πâ‡∏≠‡∏á‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢")
        print(f"üì∏ ‡∏†‡∏≤‡∏û‡∏ó‡∏µ‡πà‡∏ñ‡πà‡∏≤‡∏¢‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î: {len(self.captured_images)} ‡∏†‡∏≤‡∏û")
        
        if self.captured_images:
            print(f"üìÅ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÑ‡∏ß‡πâ‡∏ó‡∏µ‡πà: {self.output_folder}/")
    
    def get_captured_images(self):
        """‡∏î‡∏∂‡∏á‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏†‡∏≤‡∏û‡∏ó‡∏µ‡πà‡∏ñ‡πà‡∏≤‡∏¢"""
        return self.captured_images.copy()


def main():
    """‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏Ç‡∏≠‡∏á‡∏Å‡∏•‡πâ‡∏≠‡∏á"""
    camera = ParcelCamera(
        output_folder="parcel_images",
        camera_index=0,
        auto_capture=False,  # ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏î‡πâ‡∏ß‡∏¢‡πÇ‡∏´‡∏°‡∏î manual
        min_contour_area=50000
    )
    
    camera.run()
    
    # ‡πÅ‡∏™‡∏î‡∏á‡∏†‡∏≤‡∏û‡∏ó‡∏µ‡πà‡∏ñ‡πà‡∏≤‡∏¢
    captured = camera.get_captured_images()
    if captured:
        print("\nüìã ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏†‡∏≤‡∏û‡∏ó‡∏µ‡πà‡∏ñ‡πà‡∏≤‡∏¢:")
        for i, img in enumerate(captured, 1):
            print(f"   {i}. {img['filename']} ({'AUTO' if img['auto'] else 'MANUAL'})")


if __name__ == "__main__":
    main()