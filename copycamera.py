import cv2
import numpy as np
import os
from datetime import datetime
from typing import Optional, Tuple
import threading
import time


class ParcelCamera:
    """Real-time camera system for capturing parcel images"""
    
    def __init__(self, output_folder: str = "parcel_images", 
                 camera_index: int = 0,
                 auto_capture: bool = False,
                 min_contour_area: int = 50000):
        """
        Args:
            output_folder: à¹‚à¸Ÿà¸¥à¹€à¸”à¸­à¸£à¹Œà¸ªà¸³à¸«à¸£à¸±à¸šà¸šà¸±à¸™à¸—à¸¶à¸à¸ à¸²à¸
            camera_index: index à¸‚à¸­à¸‡à¸à¸¥à¹‰à¸­à¸‡ (0 = à¸à¸¥à¹‰à¸­à¸‡à¸«à¸¥à¸±à¸)
            auto_capture: à¸–à¹ˆà¸²à¸¢à¸ à¸²à¸à¸­à¸±à¸•à¹‚à¸™à¸¡à¸±à¸•à¸´à¹€à¸¡à¸·à¹ˆà¸­à¸•à¸£à¸§à¸ˆà¸ˆà¸±à¸šà¸§à¸±à¸•à¸–à¸¸
            min_contour_area: à¸à¸·à¹‰à¸™à¸—à¸µà¹ˆà¸‚à¸±à¹‰à¸™à¸•à¹ˆà¸³à¸ªà¸³à¸«à¸£à¸±à¸šà¸•à¸£à¸§à¸ˆà¸ˆà¸±à¸šà¸à¸±à¸ªà¸”à¸¸
        """
        self.output_folder = output_folder
        self.camera_index = camera_index
        self.auto_capture = auto_capture
        self.min_contour_area = min_contour_area
        
        # à¸ªà¸£à¹‰à¸²à¸‡à¹‚à¸Ÿà¸¥à¹€à¸”à¸­à¸£à¹Œà¸–à¹‰à¸²à¸¢à¸±à¸‡à¹„à¸¡à¹ˆà¸¡à¸µ
        if not os.path.exists(output_folder):
            os.makedirs(output_folder)
            print(f"âœ… à¸ªà¸£à¹‰à¸²à¸‡à¹‚à¸Ÿà¸¥à¹€à¸”à¸­à¸£à¹Œ: {output_folder}")
        
        # Camera settings
        self.cap = None
        self.is_running = False
        self.captured_images = []
        
        # Detection settings
        self.detection_cooldown = 2.0  # à¸§à¸´à¸™à¸²à¸—à¸µ à¸à¹ˆà¸­à¸™à¸ˆà¸±à¸šà¸ à¸²à¸à¸–à¸±à¸”à¹„à¸›
        self.last_capture_time = 0
        
        # ROI (Region of Interest) settings
        self.roi_percentage = 0.7  # 70% à¸‚à¸­à¸‡à¸«à¸™à¹‰à¸²à¸ˆà¸­
        
        # Background subtraction
        self.background = None
        self.bg_frames_count = 0
        self.bg_frames_needed = 30  # à¸ˆà¸³à¸™à¸§à¸™à¹€à¸Ÿà¸£à¸¡à¸ªà¸³à¸«à¸£à¸±à¸šà¸ªà¸£à¹‰à¸²à¸‡ background
        
    def initialize_camera(self) -> bool:
        """à¹€à¸›à¸´à¸”à¸à¸¥à¹‰à¸­à¸‡"""
        try:
            self.cap = cv2.VideoCapture(self.camera_index)
            
            if not self.cap.isOpened():
                print(f"âŒ à¹„à¸¡à¹ˆà¸ªà¸²à¸¡à¸²à¸£à¸–à¹€à¸›à¸´à¸”à¸à¸¥à¹‰à¸­à¸‡ index {self.camera_index}")
                return False
            
            # à¸•à¸±à¹‰à¸‡à¸„à¹ˆà¸²à¸„à¸§à¸²à¸¡à¸¥à¸°à¹€à¸­à¸µà¸¢à¸”
            self.cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)
            self.cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)
            
            # à¹€à¸à¸´à¹ˆà¸¡à¸à¸²à¸£à¸•à¸±à¹‰à¸‡à¸„à¹ˆà¸²à¸à¸¥à¹‰à¸­à¸‡à¸ªà¸³à¸«à¸£à¸±à¸šà¸„à¸§à¸²à¸¡à¸Šà¸±à¸”à¸—à¸µà¹ˆà¸”à¸µà¸‚à¸¶à¹‰à¸™
            self.cap.set(cv2.CAP_PROP_AUTOFOCUS, 1)  # Auto focus
            self.cap.set(cv2.CAP_PROP_FOCUS, 0)  # Focus setting
            
            # à¸­à¹ˆà¸²à¸™à¸‚à¸™à¸²à¸”à¸ˆà¸£à¸´à¸‡
            self.frame_width = int(self.cap.get(cv2.CAP_PROP_FRAME_WIDTH))
            self.frame_height = int(self.cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
            
            print(f"âœ… à¹€à¸›à¸´à¸”à¸à¸¥à¹‰à¸­à¸‡à¸ªà¸³à¹€à¸£à¹‡à¸ˆ - à¸„à¸§à¸²à¸¡à¸¥à¸°à¹€à¸­à¸µà¸¢à¸”: {self.frame_width}x{self.frame_height}")
            self.is_running = True
            return True
            
        except Exception as e:
            print(f"âŒ à¸‚à¹‰à¸­à¸œà¸´à¸”à¸à¸¥à¸²à¸”à¹ƒà¸™à¸à¸²à¸£à¹€à¸›à¸´à¸”à¸à¸¥à¹‰à¸­à¸‡: {e}")
            return False
    
    def get_roi_bounds(self, frame_shape: Tuple[int, int]) -> Tuple[int, int, int, int]:
        """à¸„à¸³à¸™à¸§à¸“à¸à¸·à¹‰à¸™à¸—à¸µà¹ˆ ROI (à¸à¸£à¸­à¸šà¸ªà¹à¸à¸™)"""
        h, w = frame_shape[:2]
        
        roi_w = int(w * self.roi_percentage)
        roi_h = int(h * self.roi_percentage)
        
        x1 = (w - roi_w) // 2
        y1 = (h - roi_h) // 2
        x2 = x1 + roi_w
        y2 = y1 + roi_h
        
        return x1, y1, x2, y2
    
    def draw_roi_frame(self, frame: np.ndarray, detected: bool = False) -> np.ndarray:
        """à¸§à¸²à¸”à¸à¸£à¸­à¸š ROI à¹à¸¥à¸° UI"""
        h, w = frame.shape[:2]
        x1, y1, x2, y2 = self.get_roi_bounds(frame.shape)
        
        # à¸ªà¸µà¸à¸£à¸­à¸š (à¹€à¸‚à¸µà¸¢à¸§ = à¸•à¸£à¸§à¸ˆà¸ˆà¸±à¸š, à¸Ÿà¹‰à¸² = à¸›à¸à¸•à¸´)
        color = (0, 255, 0) if detected else (255, 200, 0)
        thickness = 3 if detected else 2
        
        # à¸§à¸²à¸”à¸à¸£à¸­à¸šà¸«à¸¥à¸±à¸
        cv2.rectangle(frame, (x1, y1), (x2, y2), color, thickness)
        
        # à¸§à¸²à¸”à¸¡à¸¸à¸¡à¹€à¸™à¹‰à¸™ (corner markers)
        corner_length = 40
        corner_thickness = 5
        
        corners = [
            (x1, y1), (x2, y1),  # à¸šà¸™à¸‹à¹‰à¸²à¸¢, à¸šà¸™à¸‚à¸§à¸²
            (x1, y2), (x2, y2)   # à¸¥à¹ˆà¸²à¸‡à¸‹à¹‰à¸²à¸¢, à¸¥à¹ˆà¸²à¸‡à¸‚à¸§à¸²
        ]
        
        for i, (cx, cy) in enumerate(corners):
            if i == 0:  # à¸šà¸™à¸‹à¹‰à¸²à¸¢
                cv2.line(frame, (cx, cy), (cx + corner_length, cy), color, corner_thickness)
                cv2.line(frame, (cx, cy), (cx, cy + corner_length), color, corner_thickness)
            elif i == 1:  # à¸šà¸™à¸‚à¸§à¸²
                cv2.line(frame, (cx, cy), (cx - corner_length, cy), color, corner_thickness)
                cv2.line(frame, (cx, cy), (cx, cy + corner_length), color, corner_thickness)
            elif i == 2:  # à¸¥à¹ˆà¸²à¸‡à¸‹à¹‰à¸²à¸¢
                cv2.line(frame, (cx, cy), (cx + corner_length, cy), color, corner_thickness)
                cv2.line(frame, (cx, cy), (cx, cy - corner_length), color, corner_thickness)
            elif i == 3:  # à¸¥à¹ˆà¸²à¸‡à¸‚à¸§à¸²
                cv2.line(frame, (cx, cy), (cx - corner_length, cy), color, corner_thickness)
                cv2.line(frame, (cx, cy), (cx, cy - corner_length), color, corner_thickness)
        
        # à¹€à¸ªà¹‰à¸™à¸à¸¶à¹ˆà¸‡à¸à¸¥à¸²à¸‡ (crosshair)
        center_x, center_y = w // 2, h // 2
        cv2.line(frame, (center_x - 20, center_y), (center_x + 20, center_y), (0, 255, 255), 2)
        cv2.line(frame, (center_x, center_y - 20), (center_x, center_y + 20), (0, 255, 255), 2)
        
        # Text overlay - Header
        header_bg = np.zeros((80, w, 3), dtype=np.uint8)
        header_bg[:] = (40, 40, 40)
        frame[0:80] = cv2.addWeighted(frame[0:80], 0.3, header_bg, 0.7, 0)
        
        cv2.putText(frame, "PARCEL SCANNER", (20, 35), 
                    cv2.FONT_HERSHEY_DUPLEX, 1.0, (255, 255, 255), 2)
        cv2.putText(frame, f"Images: {len(self.captured_images)}", (20, 65), 
                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (200, 200, 200), 1)
        
        # Status text
        if detected:
            status_text = "PARCEL DETECTED!"
            cv2.putText(frame, status_text, (w - 350, 35), 
                        cv2.FONT_HERSHEY_DUPLEX, 0.8, (0, 255, 0), 2)
        
        # Instructions - Footer
        footer_y = h - 100
        instructions = [
            "SPACE: Capture",
            "C: Clear All",
            "A: Auto Mode",
            "Q/ESC: Exit"
        ]
        
        footer_bg = np.zeros((100, w, 3), dtype=np.uint8)
        footer_bg[:] = (40, 40, 40)
        frame[footer_y:h] = cv2.addWeighted(frame[footer_y:h], 0.3, footer_bg, 0.7, 0)
        
        for i, instruction in enumerate(instructions):
            x_pos = 20 + (i * 200)
            cv2.putText(frame, instruction, (x_pos, footer_y + 30), 
                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)
        
        mode_text = f"Mode: {'AUTO' if self.auto_capture else 'MANUAL'}"
        cv2.putText(frame, mode_text, (w - 200, footer_y + 30), 
                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 200, 0), 2)
        
        return frame
    
    def detect_parcel(self, frame: np.ndarray) -> Tuple[bool, Optional[np.ndarray]]:
        """à¸•à¸£à¸§à¸ˆà¸ˆà¸±à¸šà¸à¸±à¸ªà¸”à¸¸à¹ƒà¸™à¸à¸£à¸­à¸š ROI"""
        x1, y1, x2, y2 = self.get_roi_bounds(frame.shape)
        roi = frame[y1:y2, x1:x2]
        
        # à¹à¸›à¸¥à¸‡à¹€à¸›à¹‡à¸™ grayscale à¹€à¸‰à¸à¸²à¸°à¸ªà¸³à¸«à¸£à¸±à¸šà¸à¸²à¸£à¸•à¸£à¸§à¸ˆà¸ˆà¸±à¸š
        gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)
        
        # à¸¥à¸” noise
        blurred = cv2.GaussianBlur(gray, (5, 5), 0)
        
        # Edge detection
        edges = cv2.Canny(blurred, 50, 150)
        
        # à¸«à¸² contours
        contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        
        # à¸«à¸² contour à¸—à¸µà¹ˆà¹ƒà¸«à¸à¹ˆà¸—à¸µà¹ˆà¸ªà¸¸à¸”
        detected = False
        largest_contour = None
        
        if contours:
            largest_contour = max(contours, key=cv2.contourArea)
            area = cv2.contourArea(largest_contour)
            
            if area > self.min_contour_area:
                detected = True
        
        return detected, roi
    
    def capture_image(self, frame: np.ndarray, auto: bool = False) -> Optional[str]:
        """à¸šà¸±à¸™à¸—à¸¶à¸à¸ à¸²à¸à¸à¸±à¸ªà¸”à¸¸"""
        # à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸š cooldown (à¸ªà¸³à¸«à¸£à¸±à¸š auto capture)
        if auto:
            current_time = time.time()
            if current_time - self.last_capture_time < self.detection_cooldown:
                return None
            self.last_capture_time = current_time
        
        # à¸ªà¸£à¹‰à¸²à¸‡à¸Šà¸·à¹ˆà¸­à¹„à¸Ÿà¸¥à¹Œ
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S_%f")[:-3]
        filename = f"parcel_{timestamp}.jpg"
        filepath = os.path.join(self.output_folder, filename)
        
        # à¸šà¸±à¸™à¸—à¸¶à¸à¸ à¸²à¸
        try:
            # Crop ROI
            x1, y1, x2, y2 = self.get_roi_bounds(frame.shape)
            roi = frame[y1:y2, x1:x2]
            
            # à¸šà¸±à¸™à¸—à¸¶à¸à¸”à¹‰à¸§à¸¢à¸„à¸¸à¸“à¸ à¸²à¸à¸ªà¸¹à¸‡ (à¸šà¸±à¸™à¸—à¸¶à¸à¸ à¸²à¸ roi à¸•à¹‰à¸™à¸‰à¸šà¸±à¸š)
            cv2.imwrite(filepath, roi, [cv2.IMWRITE_JPEG_QUALITY, 95])
            
            self.captured_images.append({
                'filename': filename,
                'filepath': filepath,
                'timestamp': timestamp,
                'auto': auto
            })
            
            print(f"ğŸ“¸ {'[AUTO]' if auto else '[MANUAL]'} à¸šà¸±à¸™à¸—à¸¶à¸à¸ à¸²à¸: {filename}")
            return filepath
            
        except Exception as e:
            print(f"âŒ à¹„à¸¡à¹ˆà¸ªà¸²à¸¡à¸²à¸£à¸–à¸šà¸±à¸™à¸—à¸¶à¸à¸ à¸²à¸: {e}")
            return None
    
    def clear_captured_images(self):
        """à¸¥à¸šà¸ à¸²à¸à¸—à¸µà¹ˆà¸–à¹ˆà¸²à¸¢à¸—à¸±à¹‰à¸‡à¸«à¸¡à¸”"""
        try:
            for img_data in self.captured_images:
                filepath = img_data['filepath']
                if os.path.exists(filepath):
                    os.remove(filepath)
            
            count = len(self.captured_images)
            self.captured_images.clear()
            print(f"ğŸ—‘ï¸  à¸¥à¸šà¸ à¸²à¸à¸—à¸±à¹‰à¸‡à¸«à¸¡à¸” ({count} à¹„à¸Ÿà¸¥à¹Œ)")
            
        except Exception as e:
            print(f"âš ï¸ à¸‚à¹‰à¸­à¸œà¸´à¸”à¸à¸¥à¸²à¸”à¹ƒà¸™à¸à¸²à¸£à¸¥à¸šà¸ à¸²à¸: {e}")
    
    def run(self):
        """à¹€à¸£à¸´à¹ˆà¸¡à¸à¸²à¸£à¸—à¸³à¸‡à¸²à¸™à¸‚à¸­à¸‡à¸à¸¥à¹‰à¸­à¸‡"""
        if not self.initialize_camera():
            return
        
        print("\n" + "="*60)
        print("ğŸ“· à¹€à¸›à¸´à¸”à¸à¸¥à¹‰à¸­à¸‡à¸ªà¹à¸à¸™à¸à¸±à¸ªà¸”à¸¸")
        print("="*60)
        print("âŒ¨ï¸  Controls:")
        print("   SPACE       - à¸–à¹ˆà¸²à¸¢à¸ à¸²à¸")
        print("   C           - à¸¥à¸šà¸ à¸²à¸à¸—à¸±à¹‰à¸‡à¸«à¸¡à¸”")
        print("   A           - à¸ªà¸¥à¸±à¸šà¹‚à¸«à¸¡à¸” Auto/Manual")
        print("   Q / ESC     - à¸­à¸­à¸à¸ˆà¸²à¸à¹‚à¸›à¸£à¹à¸à¸£à¸¡")
        print("="*60)
        
        try:
            while self.is_running:
                ret, frame = self.cap.read()
                
                if not ret:
                    print("âŒ à¹„à¸¡à¹ˆà¸ªà¸²à¸¡à¸²à¸£à¸–à¸­à¹ˆà¸²à¸™à¸ à¸²à¸à¸ˆà¸²à¸à¸à¸¥à¹‰à¸­à¸‡")
                    break
                
                # à¸•à¸£à¸§à¸ˆà¸ˆà¸±à¸šà¸à¸±à¸ªà¸”à¸¸
                detected, roi = self.detect_parcel(frame)
                
                # Auto capture
                if self.auto_capture and detected:
                    self.capture_image(frame, auto=True)
                
                # à¸§à¸²à¸” UI
                display_frame = self.draw_roi_frame(frame.copy(), detected)
                
                # à¹à¸ªà¸”à¸‡à¸œà¸¥
                cv2.imshow('Parcel Scanner', display_frame)
                
                # à¸£à¸±à¸šà¸„à¸³à¸ªà¸±à¹ˆà¸‡à¸ˆà¸²à¸à¸„à¸µà¸¢à¹Œà¸šà¸­à¸£à¹Œà¸”
                key = cv2.waitKey(1) & 0xFF
                
                if key == ord(' '):  # Space - à¸–à¹ˆà¸²à¸¢à¸ à¸²à¸
                    self.capture_image(frame, auto=False)
                
                elif key == ord('c') or key == ord('C'):  # C - à¸¥à¸šà¸—à¸±à¹‰à¸‡à¸«à¸¡à¸”
                    self.clear_captured_images()
                
                elif key == ord('a') or key == ord('A'):  # A - à¸ªà¸¥à¸±à¸šà¹‚à¸«à¸¡à¸”
                    self.auto_capture = not self.auto_capture
                    mode = "AUTO" if self.auto_capture else "MANUAL"
                    print(f"ğŸ”„ à¸ªà¸¥à¸±à¸šà¹‚à¸«à¸¡à¸”à¹€à¸›à¹‡à¸™: {mode}")
                
                elif key == ord('q') or key == ord('Q') or key == 27:  # Q/ESC - à¸­à¸­à¸
                    print("\nğŸ‘‹ à¸à¸³à¸¥à¸±à¸‡à¸›à¸´à¸”à¸à¸¥à¹‰à¸­à¸‡...")
                    break
        
        except KeyboardInterrupt:
            print("\nâš ï¸ à¸«à¸¢à¸¸à¸”à¸à¸²à¸£à¸—à¸³à¸‡à¸²à¸™à¹‚à¸”à¸¢à¸œà¸¹à¹‰à¹ƒà¸Šà¹‰")
        
        finally:
            self.cleanup()
    
    def cleanup(self):
        """à¸›à¸´à¸”à¸à¸¥à¹‰à¸­à¸‡à¹à¸¥à¸°à¸—à¸³à¸„à¸§à¸²à¸¡à¸ªà¸°à¸­à¸²à¸”"""
        self.is_running = False
        
        if self.cap is not None:
            self.cap.release()
        
        cv2.destroyAllWindows()
        
        print(f"\nâœ… à¸›à¸´à¸”à¸à¸¥à¹‰à¸­à¸‡à¹€à¸£à¸µà¸¢à¸šà¸£à¹‰à¸­à¸¢")
        print(f"ğŸ“¸ à¸ à¸²à¸à¸—à¸µà¹ˆà¸–à¹ˆà¸²à¸¢à¸—à¸±à¹‰à¸‡à¸«à¸¡à¸”: {len(self.captured_images)} à¸ à¸²à¸")
        
        if self.captured_images:
            print(f"ğŸ“ à¸šà¸±à¸™à¸—à¸¶à¸à¹„à¸§à¹‰à¸—à¸µà¹ˆ: {self.output_folder}/")
    
    def get_captured_images(self):
        """à¸”à¸¶à¸‡à¸£à¸²à¸¢à¸à¸²à¸£à¸ à¸²à¸à¸—à¸µà¹ˆà¸–à¹ˆà¸²à¸¢"""
        return self.captured_images.copy()


def main():
    """à¸—à¸”à¸ªà¸­à¸šà¸à¸²à¸£à¸—à¸³à¸‡à¸²à¸™à¸‚à¸­à¸‡à¸à¸¥à¹‰à¸­à¸‡"""
    camera = ParcelCamera(
        output_folder="parcel_images",
        camera_index=0,
        auto_capture=False,  # à¹€à¸£à¸´à¹ˆà¸¡à¸”à¹‰à¸§à¸¢à¹‚à¸«à¸¡à¸” manual
        min_contour_area=50000
    )
    
    camera.run()
    
    # à¹à¸ªà¸”à¸‡à¸ à¸²à¸à¸—à¸µà¹ˆà¸–à¹ˆà¸²à¸¢
    captured = camera.get_captured_images()
    if captured:
        print("\nğŸ“‹ à¸£à¸²à¸¢à¸à¸²à¸£à¸ à¸²à¸à¸—à¸µà¹ˆà¸–à¹ˆà¸²à¸¢:")
        for i, img in enumerate(captured, 1):
            print(f"   {i}. {img['filename']} ({'AUTO' if img['auto'] else 'MANUAL'})")


if __name__ == "__main__":
    main()